{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning:** There is currently a bug with tool use functionality. The issue appears to be that vLLM does not return all the token log probabilities for tool use. Further investigation is needed to determine the exact cause. For now, teaching use case-specific tool use with non-tool use models is the recommended workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import re\n",
    "from typing import TypedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class TemporalCluePuzzle(TypedDict):\n",
    "    num_clues: int\n",
    "    prompt: str\n",
    "    solution: dict[str, str]\n",
    "\n",
    "\n",
    "puzzles: list[TemporalCluePuzzle] = json.load(open(\"./data/temporal-clue/puzzles.json\"))\n",
    "val_puzzles = puzzles[:64]\n",
    "test_puzzles = puzzles[64:128]\n",
    "train_puzzles = puzzles[128:]\n",
    "random.seed(42)\n",
    "random.shuffle(train_puzzles)\n",
    "\n",
    "\n",
    "api = art.LocalAPI(wandb_project=\"agent-reinforcement-training\")\n",
    "model = await api.get_or_create_model(\n",
    "    name=\"temporal-clue-tool-use-001\",\n",
    "    base_model=\"NousResearch/Hermes-3-Llama-3.1-8B\",\n",
    ")\n",
    "\n",
    "\n",
    "async def rollout(\n",
    "    client: openai.AsyncOpenAI, puzzle: TemporalCluePuzzle\n",
    ") -> art.Trajectory:\n",
    "    messages: art.Messages = [{\"role\": \"user\", \"content\": puzzle[\"prompt\"]}]\n",
    "    tools: art.Tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_hints\",\n",
    "                \"description\": \"A function to retrieve one or two hints. No more than 3 hints may be retrieved total. \"\n",
    "                \"Each retrieved hint decreases your final accuracy score by 5%.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"num_hints\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Number of hints to retrieve (1 or 2)\",\n",
    "                            \"enum\": [1, 2],\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    chat_completion = await client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model.name,\n",
    "        max_tokens=2048,\n",
    "        tools=tools,\n",
    "        stop=[\"<|end_of_text|>\"],\n",
    "    )\n",
    "    choice = chat_completion.choices[0]\n",
    "    messages_and_choices = [*messages, choice]\n",
    "    hints = [\n",
    "        f\"The answer for {key} is {value}\" for key, value in puzzle[\"solution\"].items()\n",
    "    ]\n",
    "    random.shuffle(hints)\n",
    "    hints_shared = 0\n",
    "\n",
    "    def get_hints(function_name: str, function_arguments: str) -> str:\n",
    "        nonlocal hints_shared\n",
    "        if function_name != \"get_hints\":\n",
    "            return f\"Error: unexpected function name {function_name}\"\n",
    "        try:\n",
    "            num_hints = json.loads(function_arguments or \"{}\").get(\"num_hints\", 1)\n",
    "        except Exception:\n",
    "            return f\"Error: invalid JSON {function_arguments}\"\n",
    "        if num_hints not in {1, 2}:\n",
    "            return f\"Error: invalid number of hints {num_hints}\"\n",
    "        if num_hints + hints_shared > 3:\n",
    "            return f\"Error: cannot retrieve {num_hints} hints, already retrieved {hints_shared} hints\"\n",
    "        hints_shared += num_hints\n",
    "        content = \"Hints:\"\n",
    "        for _ in range(num_hints):\n",
    "            content += f\"\\n{hints.pop()}\"\n",
    "        return content\n",
    "\n",
    "    while tool_calls := choice.message.tool_calls:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": choice.message.content,\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tool_call.function.name,\n",
    "                            \"arguments\": tool_call.function.arguments or \"{}\",\n",
    "                        },\n",
    "                    }\n",
    "                    for tool_call in tool_calls\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        for tool_call in tool_calls:\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": get_hints(\n",
    "                        tool_call.function.name, tool_call.function.arguments\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            messages_and_choices.append(messages[-1])\n",
    "        try:\n",
    "            chat_completion = await client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=model.name,\n",
    "                max_tokens=2048,\n",
    "                stop=[\"<|end_of_text|>\"],\n",
    "                tools=tools,\n",
    "            )\n",
    "        except openai.BadRequestError:\n",
    "            # Likely incorrectly formatted tool call arguments. We'll break\n",
    "            # out of the loop and allow the model to (probably) fail.\n",
    "            print(messages[-2].get(\"tool_calls\"))\n",
    "            break\n",
    "        choice = chat_completion.choices[0]\n",
    "        messages_and_choices.append(choice)\n",
    "\n",
    "    content = choice.message.content or \"\"\n",
    "    num_correct = 0\n",
    "    for key, value in puzzle[\"solution\"].items():\n",
    "        if matches := re.findall(rf\"{key}\\. ([A-Za-z \\.:-]+)\", content):\n",
    "            match = matches[-1]\n",
    "            if match.strip().lower() == value.lower():\n",
    "                num_correct += 1\n",
    "    reward = acc = num_correct / len(puzzle[\"solution\"])\n",
    "    return art.Trajectory(\n",
    "        messages_and_choices=messages_and_choices,\n",
    "        reward=reward - hints_shared * 0.05,\n",
    "        metrics={\"acc\": acc, \"hints\": hints_shared},\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "\n",
    "stride = 32\n",
    "for i in range(await model.get_iteration(), 1_000):\n",
    "    async with model.openai_client(\n",
    "        estimated_completion_tokens=180, tool_use=True, verbosity=2\n",
    "    ) as openai_client:\n",
    "        val_groups, train_groups = await asyncio.gather(\n",
    "            art.gather_trajectories(\n",
    "                (\n",
    "                    (rollout(openai_client, puzzle) for _ in range(2))\n",
    "                    for puzzle in val_puzzles\n",
    "                ),\n",
    "                pbar_desc=\"val\",\n",
    "                stream_chat_completions=8,\n",
    "            ),\n",
    "            art.gather_trajectories(\n",
    "                (\n",
    "                    (rollout(openai_client, puzzle) for _ in range(50))\n",
    "                    for puzzle in train_puzzles[i * stride : (i + 1) * stride]\n",
    "                ),\n",
    "                pbar_desc=\"train\",\n",
    "            ),\n",
    "        )\n",
    "    await model.log(val_groups)\n",
    "    await model.clear_iterations()\n",
    "    await model.tune(\n",
    "        train_groups, config=art.TuneConfig(plot_tensors=True, verbosity=2)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
